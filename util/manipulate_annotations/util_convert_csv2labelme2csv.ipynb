{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "#read csvs\n",
    "DATASET = '.\\\\dataset'\n",
    "EXPERIMENT_NAME = 'baseline'\n",
    "ANNOTATION_OUTPUT = 'annotation'\n",
    "ANNOTATION_BACK_OUTPUT = 'annotation_back'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qr_codes = pd.read_csv(f'{DATASET}/{EXPERIMENT_NAME}/qr_codes_all.csv', dtype={'image_id': str, 'object_id': str})\n",
    "fips = pd.read_csv(f'{DATASET}/{EXPERIMENT_NAME}/fips_all.csv', dtype={'image_id': str, 'object_id': str})\n",
    "\n",
    "train = pd.read_csv(f'{DATASET}/{EXPERIMENT_NAME}/qr_codes_train.csv', dtype={'image_id': str, 'object_id': str})\n",
    "valid = pd.read_csv(f'{DATASET}/{EXPERIMENT_NAME}/qr_codes_valid.csv', dtype={'image_id': str, 'object_id': str})\n",
    "test = pd.read_csv(f'{DATASET}/{EXPERIMENT_NAME}/qr_codes_test.csv', dtype={'image_id': str, 'object_id': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Dataset Annotations to Labelme format: 100%|██████████| 767/767 [00:04<00:00, 155.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# CSV to JSONs\n",
    "input = qr_codes['image_id'].unique()\n",
    "\n",
    "def is_a_small_qrcode(xmin, ymin, xmax, ymax, width, height):\n",
    "    xmin_scaled = xmin * 480 / width\n",
    "    ymin_scaled = ymin * 480 / height\n",
    "    xmax_scaled = xmax * 480 / width\n",
    "    ymax_scaled = ymax * 480 / height\n",
    "    area_scaled = abs(xmax_scaled-xmin_scaled) * abs(ymax_scaled-ymin_scaled)\n",
    "    return area_scaled < 500 \n",
    "\n",
    "for i in tqdm(range(len(input)), desc='Converting Dataset Annotations to Labelme format'):\n",
    "    entry = input[i]\n",
    "\n",
    "    entry_qr_codes = qr_codes[qr_codes['image_id']==entry].reset_index()\n",
    "    entry_fips = fips[fips['image_id']==entry].reset_index()\n",
    "\n",
    "    entry_set = 'not_used'\n",
    "    if entry in train['image_id'].values:\n",
    "        entry_set = 'train'\n",
    "    elif entry in valid['image_id'].values:\n",
    "        entry_set = 'valid'\n",
    "    elif entry in test['image_id'].values:\n",
    "        entry_set = 'test'\n",
    "\n",
    "    # Data to be written\n",
    "    attribute_has_small_qrcode = False\n",
    "    dictionary ={\n",
    "        \"version\": \"5.0.1\",\n",
    "        \"flags\": {f'{entry_set}': True, 'inconsistency_missing_bb': False, 'inconsistency_bb_misplaced': False, 'inconsistency_other': False, 'attribute_has_occlusion': False, 'attribute_is_unfocused': False,  'attribute_has_small_qrcode': False},\n",
    "        \"imagePath\": f'..\\\\images\\\\{entry}.jpg',\n",
    "        \"imageData\": None,\n",
    "        \"imageHeight\": eval(str(entry_qr_codes.iloc[0][\"image_height\"])),\n",
    "        \"imageWidth\": eval(str(entry_qr_codes.iloc[0][\"image_width\"]))\n",
    "    }\n",
    "    \n",
    "    shapes = []\n",
    "    for index, row in entry_qr_codes.iterrows():\n",
    "        if is_a_small_qrcode(row['xmin'], row['ymin'], row['xmax'], row['ymax'], dictionary['imageWidth'], dictionary['imageHeight']):\n",
    "            attribute_has_small_qrcode = True\n",
    "            dictionary['flags']['attribute_has_small_qrcode'] = True\n",
    "\n",
    "        shape = {\n",
    "            \"label\": \"qr_code\",\n",
    "            \"points\": [\n",
    "                [\n",
    "                eval(str(row['xmin'])),\n",
    "                eval(str(row['ymin']))\n",
    "                ],\n",
    "                [\n",
    "                eval(str(row['xmax'])),\n",
    "                eval(str(row['ymax']))\n",
    "                ]\n",
    "            ],\n",
    "            \"group_id\": eval(str(row['object_id'])),\n",
    "            \"shape_type\": \"rectangle\",\n",
    "            \"flags\": {}\n",
    "        }\n",
    "        shapes.append(shape)\n",
    "\n",
    "    for index, row in entry_fips.iterrows():\n",
    "        shape = {\n",
    "            \"label\": \"fips\",\n",
    "            \"points\": [\n",
    "                [\n",
    "                eval(str(row['xmin'])),\n",
    "                eval(str(row['ymin']))\n",
    "                ],\n",
    "                [\n",
    "                eval(str(row['xmax'])),\n",
    "                eval(str(row['ymax']))\n",
    "                ]\n",
    "            ],\n",
    "            \"group_id\": eval(str(row['object_id'])),\n",
    "            \"shape_type\": \"rectangle\",\n",
    "            \"flags\": {}\n",
    "        }\n",
    "        shapes.append(shape)\n",
    "\n",
    "    dictionary['shapes'] = shapes\n",
    "\n",
    "    with open(f'{DATASET}/{EXPERIMENT_NAME}/{ANNOTATION_OUTPUT}/{entry}.json', \"w\") as outfile:\n",
    "        json.dump(dictionary, outfile)\n",
    "\n",
    "    # print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Comando para executar o Labelme sem salvar cópia da imagem na anotação **\n",
    "```\n",
    "Labelme.exe --nodata\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From JSONs to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading source json annotations: 100%|██████████| 767/767 [00:00<00:00, 4309.04it/s]\n",
      "Writing resulting CSV files.: 100%|██████████| 8/8 [00:00<00:00, 14.54it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "csv_output_names = ['qr_codes_all', 'qr_codes_train', 'qr_codes_valid', 'qr_codes_test', 'fips_all', 'fips_train', 'fips_valid', 'fips_test']\n",
    "lists = {}\n",
    "\n",
    "# Initializing output lists\n",
    "for name in csv_output_names:\n",
    "    lists[name] = []\n",
    "\n",
    "\n",
    "json_filenames = glob(f\"{DATASET}\\\\{EXPERIMENT_NAME}\\\\{ANNOTATION_OUTPUT}\\\\*.json\")\n",
    "for filename in tqdm(json_filenames, desc='Reading source json annotations'):\n",
    "    file = open(filename)\n",
    "    data = json.load(file)\n",
    "    image_id = Path(data['imagePath']).stem\n",
    "    image_height = data['imageHeight']\n",
    "    image_width = data['imageWidth']\n",
    "    shapes = data['shapes']\n",
    "    train = 'train' in data['flags']\n",
    "    valid = 'valid' in data['flags']\n",
    "    test = 'test' in data['flags']\n",
    "\n",
    "    qr_code_list = []\n",
    "    fips_list = []\n",
    "    for shape in shapes:\n",
    "        xmin = shape['points'][0][0]\n",
    "        ymin = shape['points'][0][1]\n",
    "        xmax = shape['points'][1][0]\n",
    "        ymax = shape['points'][1][1]\n",
    "        object_id = shape['group_id']\n",
    "\n",
    "        current = [image_id, image_height, image_width, object_id, 'not_defined', xmin, ymin, xmax, ymax ]\n",
    "\n",
    "        if shape['label'] == 'qr_code':\n",
    "            current[4] = 'qr_code'\n",
    "            lists['qr_codes_all'].append(current)\n",
    "            if train:\n",
    "                lists['qr_codes_train'].append(current)\n",
    "            elif valid:\n",
    "                lists['qr_codes_valid'].append(current)\n",
    "            elif test:\n",
    "                lists['qr_codes_test'].append(current)\n",
    "        else:\n",
    "            current[4] = 'fip'\n",
    "            lists['fips_all'].append(current)\n",
    "            if train:\n",
    "                lists['fips_train'].append(current)\n",
    "            elif valid:\n",
    "                lists['fips_valid'].append(current)\n",
    "            elif test:\n",
    "                lists['fips_test'].append(current)\n",
    "    file.close()\n",
    "\n",
    "for name in tqdm(csv_output_names, desc='Writing resulting CSV files.') :\n",
    "    header = [ 'image_id', 'image_height', 'image_width', 'object_id', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    df = pd.DataFrame(lists[name], columns = header)\n",
    "    df = df.astype({\"xmin\": int, \"ymin\": int, \"xmax\": int, \"ymax\": int}, errors='raise') \n",
    "    df.sort_values(by=['object_id', 'xmin', 'ymin'], inplace=True)\n",
    "    df.to_csv(f'{DATASET}/{EXPERIMENT_NAME}/{ANNOTATION_BACK_OUTPUT}/{name}.csv', index=False, line_terminator='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting annotated flags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading source json annotations: 100%|██████████| 767/767 [00:00<00:00, 3723.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"all\": {\n",
      "        \"attribute_has_occlusion\": 23,\n",
      "        \"attribute_has_small_qrcode\": 54,\n",
      "        \"attribute_is_unfocused\": 24,\n",
      "        \"count\": 767,\n",
      "        \"inconsistency_bb_misplaced\": 26,\n",
      "        \"inconsistency_missing_bb\": 9,\n",
      "        \"inconsistency_other\": 2\n",
      "    },\n",
      "    \"test\": {\n",
      "        \"attribute_has_occlusion\": 6,\n",
      "        \"attribute_has_small_qrcode\": 5,\n",
      "        \"attribute_is_unfocused\": 4,\n",
      "        \"count\": 100,\n",
      "        \"inconsistency_bb_misplaced\": 7,\n",
      "        \"inconsistency_missing_bb\": 1,\n",
      "        \"inconsistency_other\": 0\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"attribute_has_occlusion\": 13,\n",
      "        \"attribute_has_small_qrcode\": 41,\n",
      "        \"attribute_is_unfocused\": 16,\n",
      "        \"count\": 567,\n",
      "        \"inconsistency_bb_misplaced\": 17,\n",
      "        \"inconsistency_missing_bb\": 6,\n",
      "        \"inconsistency_other\": 2\n",
      "    },\n",
      "    \"valid\": {\n",
      "        \"attribute_has_occlusion\": 4,\n",
      "        \"attribute_has_small_qrcode\": 8,\n",
      "        \"attribute_is_unfocused\": 4,\n",
      "        \"count\": 100,\n",
      "        \"inconsistency_bb_misplaced\": 2,\n",
      "        \"inconsistency_missing_bb\": 2,\n",
      "        \"inconsistency_other\": 0\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "report = {\n",
    "    'all': {'count': 0},\n",
    "    'train': {'count': 0},\n",
    "    'valid': {'count': 0},\n",
    "    'test': {'count': 0}\n",
    "}\n",
    "\n",
    "json_filenames = glob(f\"{DATASET}\\\\{EXPERIMENT_NAME}\\\\{ANNOTATION_OUTPUT}\\\\*.json\")\n",
    "for filename in tqdm(json_filenames, desc='Reading source json annotations'):\n",
    "    file = open(filename)\n",
    "    data = json.load(file)\n",
    "    image_id = Path(data['imagePath']).stem\n",
    "    train = 'train' in data['flags']\n",
    "    valid = 'valid' in data['flags']\n",
    "    test = 'test' in data['flags']\n",
    "    flags = data['flags']\n",
    "    flags.pop('train', None)\n",
    "    flags.pop('valid', None)\n",
    "    flags.pop('test', None)\n",
    "    flags.pop('small_qrcode', None)\n",
    "\n",
    "    report['all']['count'] += 1    \n",
    "    for flag in flags.keys():\n",
    "        if flags[flag]:\n",
    "            if flag not in report['all']:\n",
    "                report['all'][flag] = 0\n",
    "            if flag not in report['train']:\n",
    "                report['train'][flag] = 0\n",
    "            if flag not in report['valid']:\n",
    "                report['valid'][flag] = 0\n",
    "            if flag not in report['test']:\n",
    "                report['test'][flag] = 0\n",
    "\n",
    "            report['all'][flag] += 1\n",
    "\n",
    "            if train:\n",
    "                report['train'][flag] += 1\n",
    "            elif valid:\n",
    "                report['valid'][flag] += 1\n",
    "            elif test:\n",
    "                report['test'][flag] += 1\n",
    "\n",
    "    if train:\n",
    "        report['train']['count'] += 1\n",
    "    elif valid:\n",
    "        report['valid']['count'] += 1\n",
    "    elif test:\n",
    "        report['test']['count'] += 1\n",
    "\n",
    "# print(report)\n",
    "print(json.dumps(report, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading source json annotations: 100%|██████████| 767/767 [00:00<00:00, 4565.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0193927093', '1134131119', '1213992780', '1476633170', '2124747258', '2126492335', '2332977452', '2423843117', '2425729926', '2468137356', '2880662710', '2943752525', '2961178381', '2985146218', '2986368381', '4059282918', '4352836095', '4353596623', '4353977850', '4354342598', '4413934670', '4413992286', '4567642653', '4597824773', '4957719411', '5121473172']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "search_in = 'all'\n",
    "what = 'inconsistency_bb_misplaced'\n",
    "\n",
    "result = []\n",
    "\n",
    "json_filenames = glob(f\"{DATASET}\\\\{EXPERIMENT_NAME}\\\\{ANNOTATION_OUTPUT}\\\\*.json\")\n",
    "for filename in tqdm(json_filenames, desc='Reading source json annotations'):\n",
    "    file = open(filename)\n",
    "    data = json.load(file)\n",
    "    image_id = Path(data['imagePath']).stem\n",
    "    train = 'train' in data['flags']\n",
    "    valid = 'valid' in data['flags']\n",
    "    test = 'test' in data['flags']\n",
    "    flags = data['flags']\n",
    "\n",
    "    if flags[what]:\n",
    "        if search_in == 'all':\n",
    "            result.append(image_id)\n",
    "        elif search_in == 'train':\n",
    "            if train:\n",
    "                result.append(image_id)\n",
    "        elif search_in == 'valid':\n",
    "            if valid:\n",
    "                result.append(image_id)\n",
    "        elif search_in == 'test':\n",
    "            if test:\n",
    "                result.append(image_id)\n",
    "\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "692e0e5b2dac9535ba397df32516123d15cee642b64f5380d2fb21772a29b53a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('qrcode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
